{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddfd9b1f-3768-4c7d-ae37-f2d9b6e2b272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas.io.sql as psql\n",
    "# 자료를 DataFrame(일종의 Table, Relation: Series의 집합체)과 Series(일종의 Column)로 리리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6087859-710d-4294-af45-756118ed0621",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52f8d224-be11-4534-a62a-a7ebbefe471c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg.connect(host='localhost', port='5432', dbname='postgres', user='postgres', password='2024')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59c007f8-2063-45de-8985-8b8ca9f054ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "psycopg.Connection"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(conn) # type, help, print를 적극 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e15ff16-50b1-41fb-ac1e-e84ba7ea594c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module pandas.io.sql in pandas.io:\n",
      "\n",
      "NAME\n",
      "    pandas.io.sql\n",
      "\n",
      "DESCRIPTION\n",
      "    Collection of query wrappers / abstractions to both facilitate data\n",
      "    retrieval and to reduce dependency on DB-specific API.\n",
      "\n",
      "CLASSES\n",
      "    abc.ABC(builtins.object)\n",
      "        PandasSQL(pandas.core.base.PandasObject, abc.ABC)\n",
      "            ADBCDatabase\n",
      "            SQLDatabase\n",
      "            SQLiteDatabase\n",
      "    builtins.object\n",
      "        BaseEngine\n",
      "            SQLAlchemyEngine\n",
      "    pandas.core.base.PandasObject(pandas.core.accessor.DirNamesMixin)\n",
      "        PandasSQL(pandas.core.base.PandasObject, abc.ABC)\n",
      "            ADBCDatabase\n",
      "            SQLDatabase\n",
      "            SQLiteDatabase\n",
      "        SQLTable\n",
      "            SQLiteTable\n",
      "\n",
      "    class ADBCDatabase(PandasSQL)\n",
      "     |  ADBCDatabase(con) -> 'None'\n",
      "     |\n",
      "     |  This class enables conversion between DataFrame and SQL databases\n",
      "     |  using ADBC to handle DataBase abstraction.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  con : adbc_driver_manager.dbapi.Connection\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      ADBCDatabase\n",
      "     |      PandasSQL\n",
      "     |      pandas.core.base.PandasObject\n",
      "     |      pandas.core.accessor.DirNamesMixin\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, con) -> 'None'\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  execute(self, sql: 'str | Select | TextClause', params=None)\n",
      "     |\n",
      "     |  has_table(self, name: 'str', schema: 'str | None' = None) -> 'bool'\n",
      "     |\n",
      "     |  read_query(\n",
      "     |      self,\n",
      "     |      sql: 'str',\n",
      "     |      index_col: 'str | list[str] | None' = None,\n",
      "     |      coerce_float: 'bool' = True,\n",
      "     |      parse_dates=None,\n",
      "     |      params=None,\n",
      "     |      chunksize: 'int | None' = None,\n",
      "     |      dtype: 'DtypeArg | None' = None,\n",
      "     |      dtype_backend: \"DtypeBackend | Literal['numpy']\" = 'numpy'\n",
      "     |  ) -> 'DataFrame | Iterator[DataFrame]'\n",
      "     |      Read SQL query into a DataFrame.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sql : str\n",
      "     |          SQL query to be executed.\n",
      "     |      index_col : string, optional, default: None\n",
      "     |          Column name to use as index for the returned DataFrame object.\n",
      "     |      coerce_float : bool, default True\n",
      "     |          Raises NotImplementedError\n",
      "     |      params : list, tuple or dict, optional, default: None\n",
      "     |          Raises NotImplementedError\n",
      "     |      parse_dates : list or dict, default: None\n",
      "     |          - List of column names to parse as dates.\n",
      "     |          - Dict of ``{column_name: format string}`` where format string is\n",
      "     |            strftime compatible in case of parsing string times, or is one of\n",
      "     |            (D, s, ns, ms, us) in case of parsing integer timestamps.\n",
      "     |          - Dict of ``{column_name: arg dict}``, where the arg dict\n",
      "     |            corresponds to the keyword arguments of\n",
      "     |            :func:`pandas.to_datetime` Especially useful with databases\n",
      "     |            without native Datetime support, such as SQLite.\n",
      "     |      chunksize : int, default None\n",
      "     |          Raises NotImplementedError\n",
      "     |      dtype : Type name or dict of columns\n",
      "     |          Data type for data or columns. E.g. np.float64 or\n",
      "     |          {'a': np.float64, 'b': np.int32, 'c': 'Int64'}\n",
      "     |\n",
      "     |          .. versionadded:: 1.3.0\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      DataFrame\n",
      "     |\n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      read_sql_table : Read SQL database table into a DataFrame.\n",
      "     |      read_sql\n",
      "     |\n",
      "     |  read_sql = read_query(\n",
      "     |      self,\n",
      "     |      sql: 'str',\n",
      "     |      index_col: 'str | list[str] | None' = None,\n",
      "     |      coerce_float: 'bool' = True,\n",
      "     |      parse_dates=None,\n",
      "     |      params=None,\n",
      "     |      chunksize: 'int | None' = None,\n",
      "     |      dtype: 'DtypeArg | None' = None,\n",
      "     |      dtype_backend: \"DtypeBackend | Literal['numpy']\" = 'numpy'\n",
      "     |  ) -> 'DataFrame | Iterator[DataFrame]'\n",
      "     |\n",
      "     |  read_table(\n",
      "     |      self,\n",
      "     |      table_name: 'str',\n",
      "     |      index_col: 'str | list[str] | None' = None,\n",
      "     |      coerce_float: 'bool' = True,\n",
      "     |      parse_dates=None,\n",
      "     |      columns=None,\n",
      "     |      schema: 'str | None' = None,\n",
      "     |      chunksize: 'int | None' = None,\n",
      "     |      dtype_backend: \"DtypeBackend | Literal['numpy']\" = 'numpy'\n",
      "     |  ) -> 'DataFrame | Iterator[DataFrame]'\n",
      "     |      Read SQL database table into a DataFrame.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      table_name : str\n",
      "     |          Name of SQL table in database.\n",
      "     |      coerce_float : bool, default True\n",
      "     |          Raises NotImplementedError\n",
      "     |      parse_dates : list or dict, default: None\n",
      "     |          - List of column names to parse as dates.\n",
      "     |          - Dict of ``{column_name: format string}`` where format string is\n",
      "     |            strftime compatible in case of parsing string times, or is one of\n",
      "     |            (D, s, ns, ms, us) in case of parsing integer timestamps.\n",
      "     |          - Dict of ``{column_name: arg}``, where the arg corresponds\n",
      "     |            to the keyword arguments of :func:`pandas.to_datetime`.\n",
      "     |            Especially useful with databases without native Datetime support,\n",
      "     |            such as SQLite.\n",
      "     |      columns : list, default: None\n",
      "     |          List of column names to select from SQL table.\n",
      "     |      schema : string, default None\n",
      "     |          Name of SQL schema in database to query (if database flavor\n",
      "     |          supports this).  If specified, this overwrites the default\n",
      "     |          schema of the SQL database object.\n",
      "     |      chunksize : int, default None\n",
      "     |          Raises NotImplementedError\n",
      "     |      dtype_backend : {'numpy_nullable', 'pyarrow'}, default 'numpy_nullable'\n",
      "     |          Back-end data type applied to the resultant :class:`DataFrame`\n",
      "     |          (still experimental). Behaviour is as follows:\n",
      "     |\n",
      "     |          * ``\"numpy_nullable\"``: returns nullable-dtype-backed :class:`DataFrame`\n",
      "     |            (default).\n",
      "     |          * ``\"pyarrow\"``: returns pyarrow-backed nullable :class:`ArrowDtype`\n",
      "     |            DataFrame.\n",
      "     |\n",
      "     |          .. versionadded:: 2.0\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      DataFrame\n",
      "     |\n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.read_sql_table\n",
      "     |      SQLDatabase.read_query\n",
      "     |\n",
      "     |  run_transaction(self)\n",
      "     |\n",
      "     |  to_sql(\n",
      "     |      self,\n",
      "     |      frame,\n",
      "     |      name: 'str',\n",
      "     |      if_exists: \"Literal['fail', 'replace', 'append']\" = 'fail',\n",
      "     |      index: 'bool' = True,\n",
      "     |      index_label=None,\n",
      "     |      schema: 'str | None' = None,\n",
      "     |      chunksize: 'int | None' = None,\n",
      "     |      dtype: 'DtypeArg | None' = None,\n",
      "     |      method: \"Literal['multi'] | Callable | None\" = None,\n",
      "     |      engine: 'str' = 'auto',\n",
      "     |      **engine_kwargs\n",
      "     |  ) -> 'int | None'\n",
      "     |      Write records stored in a DataFrame to a SQL database.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      frame : DataFrame\n",
      "     |      name : string\n",
      "     |          Name of SQL table.\n",
      "     |      if_exists : {'fail', 'replace', 'append'}, default 'fail'\n",
      "     |          - fail: If table exists, do nothing.\n",
      "     |          - replace: If table exists, drop it, recreate it, and insert data.\n",
      "     |          - append: If table exists, insert data. Create if does not exist.\n",
      "     |      index : boolean, default True\n",
      "     |          Write DataFrame index as a column.\n",
      "     |      index_label : string or sequence, default None\n",
      "     |          Raises NotImplementedError\n",
      "     |      schema : string, default None\n",
      "     |          Name of SQL schema in database to write to (if database flavor\n",
      "     |          supports this). If specified, this overwrites the default\n",
      "     |          schema of the SQLDatabase object.\n",
      "     |      chunksize : int, default None\n",
      "     |          Raises NotImplementedError\n",
      "     |      dtype : single type or dict of column name to SQL type, default None\n",
      "     |          Raises NotImplementedError\n",
      "     |      method : {None', 'multi', callable}, default None\n",
      "     |          Raises NotImplementedError\n",
      "     |      engine : {'auto', 'sqlalchemy'}, default 'auto'\n",
      "     |          Raises NotImplementedError if not set to 'auto'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from PandasSQL:\n",
      "     |\n",
      "     |  __enter__(self) -> 'Self'\n",
      "     |\n",
      "     |  __exit__(self, *args) -> 'None'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.base.PandasObject:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return a string representation for a particular object.\n",
      "     |\n",
      "     |  __sizeof__(self) -> 'int'\n",
      "     |      Generates the total memory usage for an object that returns\n",
      "     |      either a value or Series of values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.accessor.DirNamesMixin:\n",
      "     |\n",
      "     |  __dir__(self) -> 'list[str]'\n",
      "     |      Provide method name lookup and completion.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Only provide 'public' methods.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pandas.core.accessor.DirNamesMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "\n",
      "    class BaseEngine(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  insert_records(\n",
      "     |      self,\n",
      "     |      table: 'SQLTable',\n",
      "     |      con,\n",
      "     |      frame,\n",
      "     |      name: 'str',\n",
      "     |      index: 'bool | str | list[str] | None' = True,\n",
      "     |      schema=None,\n",
      "     |      chunksize: 'int | None' = None,\n",
      "     |      method=None,\n",
      "     |      **engine_kwargs\n",
      "     |  ) -> 'int | None'\n",
      "     |      Inserts data into already-prepared table\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "\n",
      "    class PandasSQL(pandas.core.base.PandasObject, abc.ABC)\n",
      "     |  Subclasses Should define read_query and to_sql.\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      PandasSQL\n",
      "     |      pandas.core.base.PandasObject\n",
      "     |      pandas.core.accessor.DirNamesMixin\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __enter__(self) -> 'Self'\n",
      "     |\n",
      "     |  __exit__(self, *args) -> 'None'\n",
      "     |\n",
      "     |  execute(self, sql: 'str | Select | TextClause', params=None)\n",
      "     |\n",
      "     |  has_table(self, name: 'str', schema: 'str | None' = None) -> 'bool'\n",
      "     |\n",
      "     |  read_query(\n",
      "     |      self,\n",
      "     |      sql: 'str',\n",
      "     |      index_col: 'str | list[str] | None' = None,\n",
      "     |      coerce_float: 'bool' = True,\n",
      "     |      parse_dates=None,\n",
      "     |      params=None,\n",
      "     |      chunksize: 'int | None' = None,\n",
      "     |      dtype: 'DtypeArg | None' = None,\n",
      "     |      dtype_backend: \"DtypeBackend | Literal['numpy']\" = 'numpy'\n",
      "     |  ) -> 'DataFrame | Iterator[DataFrame]'\n",
      "     |\n",
      "     |  read_table(\n",
      "     |      self,\n",
      "     |      table_name: 'str',\n",
      "     |      index_col: 'str | list[str] | None' = None,\n",
      "     |      coerce_float: 'bool' = True,\n",
      "     |      parse_dates=None,\n",
      "     |      columns=None,\n",
      "     |      schema: 'str | None' = None,\n",
      "     |      chunksize: 'int | None' = None,\n",
      "     |      dtype_backend: \"DtypeBackend | Literal['numpy']\" = 'numpy'\n",
      "     |  ) -> 'DataFrame | Iterator[DataFrame]'\n",
      "     |\n",
      "     |  to_sql(\n",
      "     |      self,\n",
      "     |      frame,\n",
      "     |      name: 'str',\n",
      "     |      if_exists: \"Literal['fail', 'replace', 'append']\" = 'fail',\n",
      "     |      index: 'bool' = True,\n",
      "     |      index_label=None,\n",
      "     |      schema=None,\n",
      "     |      chunksize: 'int | None' = None,\n",
      "     |      dtype: 'DtypeArg | None' = None,\n",
      "     |      method: \"Literal['multi'] | Callable | None\" = None,\n",
      "     |      engine: 'str' = 'auto',\n",
      "     |      **engine_kwargs\n",
      "     |  ) -> 'int | None'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset({'_create_sql_schema', 'execute', 'has...\n",
      "     |\n",
      "     |  __annotations__ = {}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.base.PandasObject:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return a string representation for a particular object.\n",
      "     |\n",
      "     |  __sizeof__(self) -> 'int'\n",
      "     |      Generates the total memory usage for an object that returns\n",
      "     |      either a value or Series of values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.accessor.DirNamesMixin:\n",
      "     |\n",
      "     |  __dir__(self) -> 'list[str]'\n",
      "     |      Provide method name lookup and completion.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Only provide 'public' methods.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pandas.core.accessor.DirNamesMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "\n",
      "    class SQLAlchemyEngine(BaseEngine)\n",
      "     |  SQLAlchemyEngine() -> 'None'\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      SQLAlchemyEngine\n",
      "     |      BaseEngine\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self) -> 'None'\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  insert_records(\n",
      "     |      self,\n",
      "     |      table: 'SQLTable',\n",
      "     |      con,\n",
      "     |      frame,\n",
      "     |      name: 'str',\n",
      "     |      index: 'bool | str | list[str] | None' = True,\n",
      "     |      schema=None,\n",
      "     |      chunksize: 'int | None' = None,\n",
      "     |      method=None,\n",
      "     |      **engine_kwargs\n",
      "     |  ) -> 'int | None'\n",
      "     |      Inserts data into already-prepared table\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from BaseEngine:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "\n",
      "    class SQLDatabase(PandasSQL)\n",
      "     |  SQLDatabase(con, schema: 'str | None' = None, need_transaction: 'bool' = False) -> 'None'\n",
      "     |\n",
      "     |  This class enables conversion between DataFrame and SQL databases\n",
      "     |  using SQLAlchemy to handle DataBase abstraction.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  con : SQLAlchemy Connectable or URI string.\n",
      "     |      Connectable to connect with the database. Using SQLAlchemy makes it\n",
      "     |      possible to use any DB supported by that library.\n",
      "     |  schema : string, default None\n",
      "     |      Name of SQL schema in database to write to (if database flavor\n",
      "     |      supports this). If None, use default schema (default).\n",
      "     |  need_transaction : bool, default False\n",
      "     |      If True, SQLDatabase will create a transaction.\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      SQLDatabase\n",
      "     |      PandasSQL\n",
      "     |      pandas.core.base.PandasObject\n",
      "     |      pandas.core.accessor.DirNamesMixin\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __exit__(self, *args) -> 'None'\n",
      "     |\n",
      "     |  __init__(\n",
      "     |      self,\n",
      "     |      con,\n",
      "     |      schema: 'str | None' = None,\n",
      "     |      need_transaction: 'bool' = False\n",
      "     |  ) -> 'None'\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  check_case_sensitive(self, name: 'str', schema: 'str | None') -> 'None'\n",
      "     |      Checks table name for issues with case-sensitivity.\n",
      "     |      Method is called after data is inserted.\n",
      "     |\n",
      "     |  drop_table(self, table_name: 'str', schema: 'str | None' = None) -> 'None'\n",
      "     |\n",
      "     |  execute(self, sql: 'str | Select | TextClause', params=None)\n",
      "     |      Simple passthrough to SQLAlchemy connectable\n",
      "     |\n",
      "     |  get_table(self, table_name: 'str', schema: 'str | None' = None) -> 'Table'\n",
      "     |\n",
      "     |  has_table(self, name: 'str', schema: 'str | None' = None) -> 'bool'\n",
      "     |\n",
      "     |  prep_table(\n",
      "     |      self,\n",
      "     |      frame,\n",
      "     |      name: 'str',\n",
      "     |      if_exists: \"Literal['fail', 'replace', 'append']\" = 'fail',\n",
      "     |      index: 'bool | str | list[str] | None' = True,\n",
      "     |      index_label=None,\n",
      "     |      schema=None,\n",
      "     |      dtype: 'DtypeArg | None' = None\n",
      "     |  ) -> 'SQLTable'\n",
      "     |      Prepares table in the database for data insertion. Creates it if needed, etc.\n",
      "     |\n",
      "     |  read_query(\n",
      "     |      self,\n",
      "     |      sql: 'str',\n",
      "     |      index_col: 'str | list[str] | None' = None,\n",
      "     |      coerce_float: 'bool' = True,\n",
      "     |      parse_dates=None,\n",
      "     |      params=None,\n",
      "     |      chunksize: 'int | None' = None,\n",
      "     |      dtype: 'DtypeArg | None' = None,\n",
      "     |      dtype_backend: \"DtypeBackend | Literal['numpy']\" = 'numpy'\n",
      "     |  ) -> 'DataFrame | Iterator[DataFrame]'\n",
      "     |      Read SQL query into a DataFrame.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sql : str\n",
      "     |          SQL query to be executed.\n",
      "     |      index_col : string, optional, default: None\n",
      "     |          Column name to use as index for the returned DataFrame object.\n",
      "     |      coerce_float : bool, default True\n",
      "     |          Attempt to convert values of non-string, non-numeric objects (like\n",
      "     |          decimal.Decimal) to floating point, useful for SQL result sets.\n",
      "     |      params : list, tuple or dict, optional, default: None\n",
      "     |          List of parameters to pass to execute method.  The syntax used\n",
      "     |          to pass parameters is database driver dependent. Check your\n",
      "     |          database driver documentation for which of the five syntax styles,\n",
      "     |          described in PEP 249's paramstyle, is supported.\n",
      "     |          Eg. for psycopg2, uses %(name)s so use params={'name' : 'value'}\n",
      "     |      parse_dates : list or dict, default: None\n",
      "     |          - List of column names to parse as dates.\n",
      "     |          - Dict of ``{column_name: format string}`` where format string is\n",
      "     |            strftime compatible in case of parsing string times, or is one of\n",
      "     |            (D, s, ns, ms, us) in case of parsing integer timestamps.\n",
      "     |          - Dict of ``{column_name: arg dict}``, where the arg dict\n",
      "     |            corresponds to the keyword arguments of\n",
      "     |            :func:`pandas.to_datetime` Especially useful with databases\n",
      "     |            without native Datetime support, such as SQLite.\n",
      "     |      chunksize : int, default None\n",
      "     |          If specified, return an iterator where `chunksize` is the number\n",
      "     |          of rows to include in each chunk.\n",
      "     |      dtype : Type name or dict of columns\n",
      "     |          Data type for data or columns. E.g. np.float64 or\n",
      "     |          {'a': np.float64, 'b': np.int32, 'c': 'Int64'}\n",
      "     |\n",
      "     |          .. versionadded:: 1.3.0\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      DataFrame\n",
      "     |\n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      read_sql_table : Read SQL database table into a DataFrame.\n",
      "     |      read_sql\n",
      "     |\n",
      "     |  read_sql = read_query(\n",
      "     |      self,\n",
      "     |      sql: 'str',\n",
      "     |      index_col: 'str | list[str] | None' = None,\n",
      "     |      coerce_float: 'bool' = True,\n",
      "     |      parse_dates=None,\n",
      "     |      params=None,\n",
      "     |      chunksize: 'int | None' = None,\n",
      "     |      dtype: 'DtypeArg | None' = None,\n",
      "     |      dtype_backend: \"DtypeBackend | Literal['numpy']\" = 'numpy'\n",
      "     |  ) -> 'DataFrame | Iterator[DataFrame]'\n",
      "     |\n",
      "     |  read_table(\n",
      "     |      self,\n",
      "     |      table_name: 'str',\n",
      "     |      index_col: 'str | list[str] | None' = None,\n",
      "     |      coerce_float: 'bool' = True,\n",
      "     |      parse_dates=None,\n",
      "     |      columns=None,\n",
      "     |      schema: 'str | None' = None,\n",
      "     |      chunksize: 'int | None' = None,\n",
      "     |      dtype_backend: \"DtypeBackend | Literal['numpy']\" = 'numpy'\n",
      "     |  ) -> 'DataFrame | Iterator[DataFrame]'\n",
      "     |      Read SQL database table into a DataFrame.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      table_name : str\n",
      "     |          Name of SQL table in database.\n",
      "     |      index_col : string, optional, default: None\n",
      "     |          Column to set as index.\n",
      "     |      coerce_float : bool, default True\n",
      "     |          Attempts to convert values of non-string, non-numeric objects\n",
      "     |          (like decimal.Decimal) to floating point. This can result in\n",
      "     |          loss of precision.\n",
      "     |      parse_dates : list or dict, default: None\n",
      "     |          - List of column names to parse as dates.\n",
      "     |          - Dict of ``{column_name: format string}`` where format string is\n",
      "     |            strftime compatible in case of parsing string times, or is one of\n",
      "     |            (D, s, ns, ms, us) in case of parsing integer timestamps.\n",
      "     |          - Dict of ``{column_name: arg}``, where the arg corresponds\n",
      "     |            to the keyword arguments of :func:`pandas.to_datetime`.\n",
      "     |            Especially useful with databases without native Datetime support,\n",
      "     |            such as SQLite.\n",
      "     |      columns : list, default: None\n",
      "     |          List of column names to select from SQL table.\n",
      "     |      schema : string, default None\n",
      "     |          Name of SQL schema in database to query (if database flavor\n",
      "     |          supports this).  If specified, this overwrites the default\n",
      "     |          schema of the SQL database object.\n",
      "     |      chunksize : int, default None\n",
      "     |          If specified, return an iterator where `chunksize` is the number\n",
      "     |          of rows to include in each chunk.\n",
      "     |      dtype_backend : {'numpy_nullable', 'pyarrow'}, default 'numpy_nullable'\n",
      "     |          Back-end data type applied to the resultant :class:`DataFrame`\n",
      "     |          (still experimental). Behaviour is as follows:\n",
      "     |\n",
      "     |          * ``\"numpy_nullable\"``: returns nullable-dtype-backed :class:`DataFrame`\n",
      "     |            (default).\n",
      "     |          * ``\"pyarrow\"``: returns pyarrow-backed nullable :class:`ArrowDtype`\n",
      "     |            DataFrame.\n",
      "     |\n",
      "     |          .. versionadded:: 2.0\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      DataFrame\n",
      "     |\n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      pandas.read_sql_table\n",
      "     |      SQLDatabase.read_query\n",
      "     |\n",
      "     |  run_transaction(self)\n",
      "     |\n",
      "     |  to_sql(\n",
      "     |      self,\n",
      "     |      frame,\n",
      "     |      name: 'str',\n",
      "     |      if_exists: \"Literal['fail', 'replace', 'append']\" = 'fail',\n",
      "     |      index: 'bool' = True,\n",
      "     |      index_label=None,\n",
      "     |      schema: 'str | None' = None,\n",
      "     |      chunksize: 'int | None' = None,\n",
      "     |      dtype: 'DtypeArg | None' = None,\n",
      "     |      method: \"Literal['multi'] | Callable | None\" = None,\n",
      "     |      engine: 'str' = 'auto',\n",
      "     |      **engine_kwargs\n",
      "     |  ) -> 'int | None'\n",
      "     |      Write records stored in a DataFrame to a SQL database.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      frame : DataFrame\n",
      "     |      name : string\n",
      "     |          Name of SQL table.\n",
      "     |      if_exists : {'fail', 'replace', 'append'}, default 'fail'\n",
      "     |          - fail: If table exists, do nothing.\n",
      "     |          - replace: If table exists, drop it, recreate it, and insert data.\n",
      "     |          - append: If table exists, insert data. Create if does not exist.\n",
      "     |      index : boolean, default True\n",
      "     |          Write DataFrame index as a column.\n",
      "     |      index_label : string or sequence, default None\n",
      "     |          Column label for index column(s). If None is given (default) and\n",
      "     |          `index` is True, then the index names are used.\n",
      "     |          A sequence should be given if the DataFrame uses MultiIndex.\n",
      "     |      schema : string, default None\n",
      "     |          Name of SQL schema in database to write to (if database flavor\n",
      "     |          supports this). If specified, this overwrites the default\n",
      "     |          schema of the SQLDatabase object.\n",
      "     |      chunksize : int, default None\n",
      "     |          If not None, then rows will be written in batches of this size at a\n",
      "     |          time.  If None, all rows will be written at once.\n",
      "     |      dtype : single type or dict of column name to SQL type, default None\n",
      "     |          Optional specifying the datatype for columns. The SQL type should\n",
      "     |          be a SQLAlchemy type. If all columns are of the same type, one\n",
      "     |          single value can be used.\n",
      "     |      method : {None', 'multi', callable}, default None\n",
      "     |          Controls the SQL insertion clause used:\n",
      "     |\n",
      "     |          * None : Uses standard SQL ``INSERT`` clause (one per row).\n",
      "     |          * 'multi': Pass multiple values in a single ``INSERT`` clause.\n",
      "     |          * callable with signature ``(pd_table, conn, keys, data_iter)``.\n",
      "     |\n",
      "     |          Details and a sample callable implementation can be found in the\n",
      "     |          section :ref:`insert method <io.sql.method>`.\n",
      "     |      engine : {'auto', 'sqlalchemy'}, default 'auto'\n",
      "     |          SQL engine library to use. If 'auto', then the option\n",
      "     |          ``io.sql.engine`` is used. The default ``io.sql.engine``\n",
      "     |          behavior is 'sqlalchemy'\n",
      "     |\n",
      "     |          .. versionadded:: 1.3.0\n",
      "     |\n",
      "     |      **engine_kwargs\n",
      "     |          Any additional kwargs are passed to the engine.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |\n",
      "     |  tables\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from PandasSQL:\n",
      "     |\n",
      "     |  __enter__(self) -> 'Self'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.base.PandasObject:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return a string representation for a particular object.\n",
      "     |\n",
      "     |  __sizeof__(self) -> 'int'\n",
      "     |      Generates the total memory usage for an object that returns\n",
      "     |      either a value or Series of values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.accessor.DirNamesMixin:\n",
      "     |\n",
      "     |  __dir__(self) -> 'list[str]'\n",
      "     |      Provide method name lookup and completion.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Only provide 'public' methods.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pandas.core.accessor.DirNamesMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "\n",
      "    class SQLTable(pandas.core.base.PandasObject)\n",
      "     |  SQLTable(\n",
      "     |      name: 'str',\n",
      "     |      pandas_sql_engine,\n",
      "     |      frame=None,\n",
      "     |      index: 'bool | str | list[str] | None' = True,\n",
      "     |      if_exists: \"Literal['fail', 'replace', 'append']\" = 'fail',\n",
      "     |      prefix: 'str' = 'pandas',\n",
      "     |      index_label=None,\n",
      "     |      schema=None,\n",
      "     |      keys=None,\n",
      "     |      dtype: 'DtypeArg | None' = None\n",
      "     |  ) -> 'None'\n",
      "     |\n",
      "     |  For mapping Pandas tables to SQL tables.\n",
      "     |  Uses fact that table is reflected by SQLAlchemy to\n",
      "     |  do better type conversions.\n",
      "     |  Also holds various flags needed to avoid having to\n",
      "     |  pass them between functions all the time.\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      SQLTable\n",
      "     |      pandas.core.base.PandasObject\n",
      "     |      pandas.core.accessor.DirNamesMixin\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(\n",
      "     |      self,\n",
      "     |      name: 'str',\n",
      "     |      pandas_sql_engine,\n",
      "     |      frame=None,\n",
      "     |      index: 'bool | str | list[str] | None' = True,\n",
      "     |      if_exists: \"Literal['fail', 'replace', 'append']\" = 'fail',\n",
      "     |      prefix: 'str' = 'pandas',\n",
      "     |      index_label=None,\n",
      "     |      schema=None,\n",
      "     |      keys=None,\n",
      "     |      dtype: 'DtypeArg | None' = None\n",
      "     |  ) -> 'None'\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  create(self) -> 'None'\n",
      "     |\n",
      "     |  exists(self)\n",
      "     |\n",
      "     |  insert(\n",
      "     |      self,\n",
      "     |      chunksize: 'int | None' = None,\n",
      "     |      method: \"Literal['multi'] | Callable | None\" = None\n",
      "     |  ) -> 'int | None'\n",
      "     |\n",
      "     |  insert_data(self) -> 'tuple[list[str], list[np.ndarray]]'\n",
      "     |\n",
      "     |  read(\n",
      "     |      self,\n",
      "     |      exit_stack: 'ExitStack',\n",
      "     |      coerce_float: 'bool' = True,\n",
      "     |      parse_dates=None,\n",
      "     |      columns=None,\n",
      "     |      chunksize: 'int | None' = None,\n",
      "     |      dtype_backend: \"DtypeBackend | Literal['numpy']\" = 'numpy'\n",
      "     |  ) -> 'DataFrame | Iterator[DataFrame]'\n",
      "     |\n",
      "     |  sql_schema(self) -> 'str'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.base.PandasObject:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return a string representation for a particular object.\n",
      "     |\n",
      "     |  __sizeof__(self) -> 'int'\n",
      "     |      Generates the total memory usage for an object that returns\n",
      "     |      either a value or Series of values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.accessor.DirNamesMixin:\n",
      "     |\n",
      "     |  __dir__(self) -> 'list[str]'\n",
      "     |      Provide method name lookup and completion.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Only provide 'public' methods.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pandas.core.accessor.DirNamesMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "\n",
      "    class SQLiteDatabase(PandasSQL)\n",
      "     |  SQLiteDatabase(con) -> 'None'\n",
      "     |\n",
      "     |  Version of SQLDatabase to support SQLite connections (fallback without\n",
      "     |  SQLAlchemy). This should only be used internally.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  con : sqlite connection object\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      SQLiteDatabase\n",
      "     |      PandasSQL\n",
      "     |      pandas.core.base.PandasObject\n",
      "     |      pandas.core.accessor.DirNamesMixin\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, con) -> 'None'\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  drop_table(self, name: 'str', schema: 'str | None' = None) -> 'None'\n",
      "     |\n",
      "     |  execute(self, sql: 'str | Select | TextClause', params=None)\n",
      "     |\n",
      "     |  get_table(self, table_name: 'str', schema: 'str | None' = None) -> 'None'\n",
      "     |\n",
      "     |  has_table(self, name: 'str', schema: 'str | None' = None) -> 'bool'\n",
      "     |\n",
      "     |  read_query(\n",
      "     |      self,\n",
      "     |      sql,\n",
      "     |      index_col=None,\n",
      "     |      coerce_float: 'bool' = True,\n",
      "     |      parse_dates=None,\n",
      "     |      params=None,\n",
      "     |      chunksize: 'int | None' = None,\n",
      "     |      dtype: 'DtypeArg | None' = None,\n",
      "     |      dtype_backend: \"DtypeBackend | Literal['numpy']\" = 'numpy'\n",
      "     |  ) -> 'DataFrame | Iterator[DataFrame]'\n",
      "     |\n",
      "     |  run_transaction(self)\n",
      "     |\n",
      "     |  to_sql(\n",
      "     |      self,\n",
      "     |      frame,\n",
      "     |      name: 'str',\n",
      "     |      if_exists: 'str' = 'fail',\n",
      "     |      index: 'bool' = True,\n",
      "     |      index_label=None,\n",
      "     |      schema=None,\n",
      "     |      chunksize: 'int | None' = None,\n",
      "     |      dtype: 'DtypeArg | None' = None,\n",
      "     |      method: \"Literal['multi'] | Callable | None\" = None,\n",
      "     |      engine: 'str' = 'auto',\n",
      "     |      **engine_kwargs\n",
      "     |  ) -> 'int | None'\n",
      "     |      Write records stored in a DataFrame to a SQL database.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      frame: DataFrame\n",
      "     |      name: string\n",
      "     |          Name of SQL table.\n",
      "     |      if_exists: {'fail', 'replace', 'append'}, default 'fail'\n",
      "     |          fail: If table exists, do nothing.\n",
      "     |          replace: If table exists, drop it, recreate it, and insert data.\n",
      "     |          append: If table exists, insert data. Create if it does not exist.\n",
      "     |      index : bool, default True\n",
      "     |          Write DataFrame index as a column\n",
      "     |      index_label : string or sequence, default None\n",
      "     |          Column label for index column(s). If None is given (default) and\n",
      "     |          `index` is True, then the index names are used.\n",
      "     |          A sequence should be given if the DataFrame uses MultiIndex.\n",
      "     |      schema : string, default None\n",
      "     |          Ignored parameter included for compatibility with SQLAlchemy\n",
      "     |          version of ``to_sql``.\n",
      "     |      chunksize : int, default None\n",
      "     |          If not None, then rows will be written in batches of this\n",
      "     |          size at a time. If None, all rows will be written at once.\n",
      "     |      dtype : single type or dict of column name to SQL type, default None\n",
      "     |          Optional specifying the datatype for columns. The SQL type should\n",
      "     |          be a string. If all columns are of the same type, one single value\n",
      "     |          can be used.\n",
      "     |      method : {None, 'multi', callable}, default None\n",
      "     |          Controls the SQL insertion clause used:\n",
      "     |\n",
      "     |          * None : Uses standard SQL ``INSERT`` clause (one per row).\n",
      "     |          * 'multi': Pass multiple values in a single ``INSERT`` clause.\n",
      "     |          * callable with signature ``(pd_table, conn, keys, data_iter)``.\n",
      "     |\n",
      "     |          Details and a sample callable implementation can be found in the\n",
      "     |          section :ref:`insert method <io.sql.method>`.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |\n",
      "     |  __annotations__ = {}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from PandasSQL:\n",
      "     |\n",
      "     |  __enter__(self) -> 'Self'\n",
      "     |\n",
      "     |  __exit__(self, *args) -> 'None'\n",
      "     |\n",
      "     |  read_table(\n",
      "     |      self,\n",
      "     |      table_name: 'str',\n",
      "     |      index_col: 'str | list[str] | None' = None,\n",
      "     |      coerce_float: 'bool' = True,\n",
      "     |      parse_dates=None,\n",
      "     |      columns=None,\n",
      "     |      schema: 'str | None' = None,\n",
      "     |      chunksize: 'int | None' = None,\n",
      "     |      dtype_backend: \"DtypeBackend | Literal['numpy']\" = 'numpy'\n",
      "     |  ) -> 'DataFrame | Iterator[DataFrame]'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.base.PandasObject:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return a string representation for a particular object.\n",
      "     |\n",
      "     |  __sizeof__(self) -> 'int'\n",
      "     |      Generates the total memory usage for an object that returns\n",
      "     |      either a value or Series of values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.accessor.DirNamesMixin:\n",
      "     |\n",
      "     |  __dir__(self) -> 'list[str]'\n",
      "     |      Provide method name lookup and completion.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Only provide 'public' methods.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pandas.core.accessor.DirNamesMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "\n",
      "    class SQLiteTable(SQLTable)\n",
      "     |  SQLiteTable(*args, **kwargs) -> 'None'\n",
      "     |\n",
      "     |  Patch the SQLTable for fallback support.\n",
      "     |  Instead of a table variable just use the Create Table statement.\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      SQLiteTable\n",
      "     |      SQLTable\n",
      "     |      pandas.core.base.PandasObject\n",
      "     |      pandas.core.accessor.DirNamesMixin\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, *args, **kwargs) -> 'None'\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  insert_statement(self, *, num_rows: 'int') -> 'str'\n",
      "     |\n",
      "     |  sql_schema(self) -> 'str'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from SQLTable:\n",
      "     |\n",
      "     |  create(self) -> 'None'\n",
      "     |\n",
      "     |  exists(self)\n",
      "     |\n",
      "     |  insert(\n",
      "     |      self,\n",
      "     |      chunksize: 'int | None' = None,\n",
      "     |      method: \"Literal['multi'] | Callable | None\" = None\n",
      "     |  ) -> 'int | None'\n",
      "     |\n",
      "     |  insert_data(self) -> 'tuple[list[str], list[np.ndarray]]'\n",
      "     |\n",
      "     |  read(\n",
      "     |      self,\n",
      "     |      exit_stack: 'ExitStack',\n",
      "     |      coerce_float: 'bool' = True,\n",
      "     |      parse_dates=None,\n",
      "     |      columns=None,\n",
      "     |      chunksize: 'int | None' = None,\n",
      "     |      dtype_backend: \"DtypeBackend | Literal['numpy']\" = 'numpy'\n",
      "     |  ) -> 'DataFrame | Iterator[DataFrame]'\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.base.PandasObject:\n",
      "     |\n",
      "     |  __repr__(self) -> 'str'\n",
      "     |      Return a string representation for a particular object.\n",
      "     |\n",
      "     |  __sizeof__(self) -> 'int'\n",
      "     |      Generates the total memory usage for an object that returns\n",
      "     |      either a value or Series of values\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pandas.core.accessor.DirNamesMixin:\n",
      "     |\n",
      "     |  __dir__(self) -> 'list[str]'\n",
      "     |      Provide method name lookup and completion.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Only provide 'public' methods.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pandas.core.accessor.DirNamesMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "\n",
      "FUNCTIONS\n",
      "    execute(sql, con, params=None)\n",
      "        Execute the given SQL query using the provided connection object.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        sql : string\n",
      "            SQL query to be executed.\n",
      "        con : SQLAlchemy connection or sqlite3 connection\n",
      "            If a DBAPI2 object, only sqlite3 is supported.\n",
      "        params : list or tuple, optional, default: None\n",
      "            List of parameters to pass to execute method.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        Results Iterable\n",
      "\n",
      "    get_engine(engine: 'str') -> 'BaseEngine'\n",
      "        return our implementation\n",
      "\n",
      "    get_schema(\n",
      "        frame,\n",
      "        name: 'str',\n",
      "        keys=None,\n",
      "        con=None,\n",
      "        dtype: 'DtypeArg | None' = None,\n",
      "        schema: 'str | None' = None\n",
      "    ) -> 'str'\n",
      "        Get the SQL db table schema for the given frame.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        frame : DataFrame\n",
      "        name : str\n",
      "            name of SQL table\n",
      "        keys : string or sequence, default: None\n",
      "            columns to use a primary key\n",
      "        con: ADBC Connection, SQLAlchemy connectable, sqlite3 connection, default: None\n",
      "            ADBC provides high performance I/O with native type support, where available.\n",
      "            Using SQLAlchemy makes it possible to use any DB supported by that\n",
      "            library\n",
      "            If a DBAPI2 object, only sqlite3 is supported.\n",
      "        dtype : dict of column name to SQL type, default None\n",
      "            Optional specifying the datatype for columns. The SQL type should\n",
      "            be a SQLAlchemy type, or a string for sqlite3 fallback connection.\n",
      "        schema: str, default: None\n",
      "            Optional specifying the schema to be used in creating the table.\n",
      "\n",
      "    has_table(table_name: 'str', con, schema: 'str | None' = None) -> 'bool'\n",
      "        Check if DataBase has named table.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        table_name: string\n",
      "            Name of SQL table.\n",
      "        con: ADBC Connection, SQLAlchemy connectable, str, or sqlite3 connection\n",
      "            ADBC provides high performance I/O with native type support, where available.\n",
      "            Using SQLAlchemy makes it possible to use any DB supported by that\n",
      "            library.\n",
      "            If a DBAPI2 object, only sqlite3 is supported.\n",
      "        schema : string, default None\n",
      "            Name of SQL schema in database to write to (if database flavor supports\n",
      "            this). If None, use default schema (default).\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        boolean\n",
      "\n",
      "    pandasSQL_builder(\n",
      "        con,\n",
      "        schema: 'str | None' = None,\n",
      "        need_transaction: 'bool' = False\n",
      "    ) -> 'PandasSQL'\n",
      "        Convenience function to return the correct PandasSQL subclass based on the\n",
      "        provided parameters.  Also creates a sqlalchemy connection and transaction\n",
      "        if necessary.\n",
      "\n",
      "    read_sql(\n",
      "        sql,\n",
      "        con,\n",
      "        index_col: 'str | list[str] | None' = None,\n",
      "        coerce_float: 'bool' = True,\n",
      "        params=None,\n",
      "        parse_dates=None,\n",
      "        columns: 'list[str] | None' = None,\n",
      "        chunksize: 'int | None' = None,\n",
      "        dtype_backend: 'DtypeBackend | lib.NoDefault' = <no_default>,\n",
      "        dtype: 'DtypeArg | None' = None\n",
      "    ) -> 'DataFrame | Iterator[DataFrame]'\n",
      "        Read SQL query or database table into a DataFrame.\n",
      "\n",
      "        This function is a convenience wrapper around ``read_sql_table`` and\n",
      "        ``read_sql_query`` (for backward compatibility). It will delegate\n",
      "        to the specific function depending on the provided input. A SQL query\n",
      "        will be routed to ``read_sql_query``, while a database table name will\n",
      "        be routed to ``read_sql_table``. Note that the delegated function might\n",
      "        have more specific notes about their functionality not listed here.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        sql : str or SQLAlchemy Selectable (select or text object)\n",
      "            SQL query to be executed or a table name.\n",
      "        con : ADBC Connection, SQLAlchemy connectable, str, or sqlite3 connection\n",
      "            ADBC provides high performance I/O with native type support, where available.\n",
      "            Using SQLAlchemy makes it possible to use any DB supported by that\n",
      "            library. If a DBAPI2 object, only sqlite3 is supported. The user is responsible\n",
      "            for engine disposal and connection closure for the ADBC connection and\n",
      "            SQLAlchemy connectable; str connections are closed automatically. See\n",
      "            `here <https://docs.sqlalchemy.org/en/20/core/connections.html>`_.\n",
      "        index_col : str or list of str, optional, default: None\n",
      "            Column(s) to set as index(MultiIndex).\n",
      "        coerce_float : bool, default True\n",
      "            Attempts to convert values of non-string, non-numeric objects (like\n",
      "            decimal.Decimal) to floating point, useful for SQL result sets.\n",
      "        params : list, tuple or dict, optional, default: None\n",
      "            List of parameters to pass to execute method.  The syntax used\n",
      "            to pass parameters is database driver dependent. Check your\n",
      "            database driver documentation for which of the five syntax styles,\n",
      "            described in PEP 249's paramstyle, is supported.\n",
      "            Eg. for psycopg2, uses %(name)s so use params={'name' : 'value'}.\n",
      "        parse_dates : list or dict, default: None\n",
      "            - List of column names to parse as dates.\n",
      "            - Dict of ``{column_name: format string}`` where format string is\n",
      "              strftime compatible in case of parsing string times, or is one of\n",
      "              (D, s, ns, ms, us) in case of parsing integer timestamps.\n",
      "            - Dict of ``{column_name: arg dict}``, where the arg dict corresponds\n",
      "              to the keyword arguments of :func:`pandas.to_datetime`\n",
      "              Especially useful with databases without native Datetime support,\n",
      "              such as SQLite.\n",
      "        columns : list, default: None\n",
      "            List of column names to select from SQL table (only used when reading\n",
      "            a table).\n",
      "        chunksize : int, default None\n",
      "            If specified, return an iterator where `chunksize` is the\n",
      "            number of rows to include in each chunk.\n",
      "        dtype_backend : {'numpy_nullable', 'pyarrow'}, default 'numpy_nullable'\n",
      "            Back-end data type applied to the resultant :class:`DataFrame`\n",
      "            (still experimental). Behaviour is as follows:\n",
      "\n",
      "            * ``\"numpy_nullable\"``: returns nullable-dtype-backed :class:`DataFrame`\n",
      "              (default).\n",
      "            * ``\"pyarrow\"``: returns pyarrow-backed nullable :class:`ArrowDtype`\n",
      "              DataFrame.\n",
      "\n",
      "            .. versionadded:: 2.0\n",
      "        dtype : Type name or dict of columns\n",
      "            Data type for data or columns. E.g. np.float64 or\n",
      "            {'a': np.float64, 'b': np.int32, 'c': 'Int64'}.\n",
      "            The argument is ignored if a table is passed instead of a query.\n",
      "\n",
      "            .. versionadded:: 2.0.0\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        DataFrame or Iterator[DataFrame]\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        read_sql_table : Read SQL database table into a DataFrame.\n",
      "        read_sql_query : Read SQL query into a DataFrame.\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        Read data from SQL via either a SQL query or a SQL tablename.\n",
      "        When using a SQLite database only SQL queries are accepted,\n",
      "        providing only the SQL tablename will result in an error.\n",
      "\n",
      "        >>> from sqlite3 import connect\n",
      "        >>> conn = connect(':memory:')\n",
      "        >>> df = pd.DataFrame(data=[[0, '10/11/12'], [1, '12/11/10']],\n",
      "        ...                   columns=['int_column', 'date_column'])\n",
      "        >>> df.to_sql(name='test_data', con=conn)\n",
      "        2\n",
      "\n",
      "        >>> pd.read_sql('SELECT int_column, date_column FROM test_data', conn)\n",
      "           int_column date_column\n",
      "        0           0    10/11/12\n",
      "        1           1    12/11/10\n",
      "\n",
      "        >>> pd.read_sql('test_data', 'postgres:///db_name')  # doctest:+SKIP\n",
      "\n",
      "        Apply date parsing to columns through the ``parse_dates`` argument\n",
      "        The ``parse_dates`` argument calls ``pd.to_datetime`` on the provided columns.\n",
      "        Custom argument values for applying ``pd.to_datetime`` on a column are specified\n",
      "        via a dictionary format:\n",
      "\n",
      "        >>> pd.read_sql('SELECT int_column, date_column FROM test_data',\n",
      "        ...             conn,\n",
      "        ...             parse_dates={\"date_column\": {\"format\": \"%d/%m/%y\"}})\n",
      "           int_column date_column\n",
      "        0           0  2012-11-10\n",
      "        1           1  2010-11-12\n",
      "\n",
      "        .. versionadded:: 2.2.0\n",
      "\n",
      "           pandas now supports reading via ADBC drivers\n",
      "\n",
      "        >>> from adbc_driver_postgresql import dbapi  # doctest:+SKIP\n",
      "        >>> with dbapi.connect('postgres:///db_name') as conn:  # doctest:+SKIP\n",
      "        ...     pd.read_sql('SELECT int_column FROM test_data', conn)\n",
      "           int_column\n",
      "        0           0\n",
      "        1           1\n",
      "\n",
      "    read_sql_query(\n",
      "        sql,\n",
      "        con,\n",
      "        index_col: 'str | list[str] | None' = None,\n",
      "        coerce_float: 'bool' = True,\n",
      "        params: 'list[Any] | Mapping[str, Any] | None' = None,\n",
      "        parse_dates: 'list[str] | dict[str, str] | None' = None,\n",
      "        chunksize: 'int | None' = None,\n",
      "        dtype: 'DtypeArg | None' = None,\n",
      "        dtype_backend: 'DtypeBackend | lib.NoDefault' = <no_default>\n",
      "    ) -> 'DataFrame | Iterator[DataFrame]'\n",
      "        Read SQL query into a DataFrame.\n",
      "\n",
      "        Returns a DataFrame corresponding to the result set of the query\n",
      "        string. Optionally provide an `index_col` parameter to use one of the\n",
      "        columns as the index, otherwise default integer index will be used.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        sql : str SQL query or SQLAlchemy Selectable (select or text object)\n",
      "            SQL query to be executed.\n",
      "        con : SQLAlchemy connectable, str, or sqlite3 connection\n",
      "            Using SQLAlchemy makes it possible to use any DB supported by that\n",
      "            library. If a DBAPI2 object, only sqlite3 is supported.\n",
      "        index_col : str or list of str, optional, default: None\n",
      "            Column(s) to set as index(MultiIndex).\n",
      "        coerce_float : bool, default True\n",
      "            Attempts to convert values of non-string, non-numeric objects (like\n",
      "            decimal.Decimal) to floating point. Useful for SQL result sets.\n",
      "        params : list, tuple or mapping, optional, default: None\n",
      "            List of parameters to pass to execute method.  The syntax used\n",
      "            to pass parameters is database driver dependent. Check your\n",
      "            database driver documentation for which of the five syntax styles,\n",
      "            described in PEP 249's paramstyle, is supported.\n",
      "            Eg. for psycopg2, uses %(name)s so use params={'name' : 'value'}.\n",
      "        parse_dates : list or dict, default: None\n",
      "            - List of column names to parse as dates.\n",
      "            - Dict of ``{column_name: format string}`` where format string is\n",
      "              strftime compatible in case of parsing string times, or is one of\n",
      "              (D, s, ns, ms, us) in case of parsing integer timestamps.\n",
      "            - Dict of ``{column_name: arg dict}``, where the arg dict corresponds\n",
      "              to the keyword arguments of :func:`pandas.to_datetime`\n",
      "              Especially useful with databases without native Datetime support,\n",
      "              such as SQLite.\n",
      "        chunksize : int, default None\n",
      "            If specified, return an iterator where `chunksize` is the number of\n",
      "            rows to include in each chunk.\n",
      "        dtype : Type name or dict of columns\n",
      "            Data type for data or columns. E.g. np.float64 or\n",
      "            {'a': np.float64, 'b': np.int32, 'c': 'Int64'}.\n",
      "\n",
      "            .. versionadded:: 1.3.0\n",
      "        dtype_backend : {'numpy_nullable', 'pyarrow'}, default 'numpy_nullable'\n",
      "            Back-end data type applied to the resultant :class:`DataFrame`\n",
      "            (still experimental). Behaviour is as follows:\n",
      "\n",
      "            * ``\"numpy_nullable\"``: returns nullable-dtype-backed :class:`DataFrame`\n",
      "              (default).\n",
      "            * ``\"pyarrow\"``: returns pyarrow-backed nullable :class:`ArrowDtype`\n",
      "              DataFrame.\n",
      "\n",
      "            .. versionadded:: 2.0\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        DataFrame or Iterator[DataFrame]\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        read_sql_table : Read SQL database table into a DataFrame.\n",
      "        read_sql : Read SQL query or database table into a DataFrame.\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        Any datetime values with time zone information parsed via the `parse_dates`\n",
      "        parameter will be converted to UTC.\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sqlalchemy import create_engine  # doctest: +SKIP\n",
      "        >>> engine = create_engine(\"sqlite:///database.db\")  # doctest: +SKIP\n",
      "        >>> with engine.connect() as conn, conn.begin():  # doctest: +SKIP\n",
      "        ...     data = pd.read_sql_table(\"data\", conn)  # doctest: +SKIP\n",
      "\n",
      "    read_sql_table(\n",
      "        table_name: 'str',\n",
      "        con,\n",
      "        schema: 'str | None' = None,\n",
      "        index_col: 'str | list[str] | None' = None,\n",
      "        coerce_float: 'bool' = True,\n",
      "        parse_dates: 'list[str] | dict[str, str] | None' = None,\n",
      "        columns: 'list[str] | None' = None,\n",
      "        chunksize: 'int | None' = None,\n",
      "        dtype_backend: 'DtypeBackend | lib.NoDefault' = <no_default>\n",
      "    ) -> 'DataFrame | Iterator[DataFrame]'\n",
      "        Read SQL database table into a DataFrame.\n",
      "\n",
      "        Given a table name and a SQLAlchemy connectable, returns a DataFrame.\n",
      "        This function does not support DBAPI connections.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        table_name : str\n",
      "            Name of SQL table in database.\n",
      "        con : SQLAlchemy connectable or str\n",
      "            A database URI could be provided as str.\n",
      "            SQLite DBAPI connection mode not supported.\n",
      "        schema : str, default None\n",
      "            Name of SQL schema in database to query (if database flavor\n",
      "            supports this). Uses default schema if None (default).\n",
      "        index_col : str or list of str, optional, default: None\n",
      "            Column(s) to set as index(MultiIndex).\n",
      "        coerce_float : bool, default True\n",
      "            Attempts to convert values of non-string, non-numeric objects (like\n",
      "            decimal.Decimal) to floating point. Can result in loss of Precision.\n",
      "        parse_dates : list or dict, default None\n",
      "            - List of column names to parse as dates.\n",
      "            - Dict of ``{column_name: format string}`` where format string is\n",
      "              strftime compatible in case of parsing string times or is one of\n",
      "              (D, s, ns, ms, us) in case of parsing integer timestamps.\n",
      "            - Dict of ``{column_name: arg dict}``, where the arg dict corresponds\n",
      "              to the keyword arguments of :func:`pandas.to_datetime`\n",
      "              Especially useful with databases without native Datetime support,\n",
      "              such as SQLite.\n",
      "        columns : list, default None\n",
      "            List of column names to select from SQL table.\n",
      "        chunksize : int, default None\n",
      "            If specified, returns an iterator where `chunksize` is the number of\n",
      "            rows to include in each chunk.\n",
      "        dtype_backend : {'numpy_nullable', 'pyarrow'}, default 'numpy_nullable'\n",
      "            Back-end data type applied to the resultant :class:`DataFrame`\n",
      "            (still experimental). Behaviour is as follows:\n",
      "\n",
      "            * ``\"numpy_nullable\"``: returns nullable-dtype-backed :class:`DataFrame`\n",
      "              (default).\n",
      "            * ``\"pyarrow\"``: returns pyarrow-backed nullable :class:`ArrowDtype`\n",
      "              DataFrame.\n",
      "\n",
      "            .. versionadded:: 2.0\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        DataFrame or Iterator[DataFrame]\n",
      "            A SQL table is returned as two-dimensional data structure with labeled\n",
      "            axes.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        read_sql_query : Read SQL query into a DataFrame.\n",
      "        read_sql : Read SQL query or database table into a DataFrame.\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        Any datetime values with time zone information will be converted to UTC.\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> pd.read_sql_table('table_name', 'postgres:///db_name')  # doctest:+SKIP\n",
      "\n",
      "    table_exists = has_table(table_name: 'str', con, schema: 'str | None' = None) -> 'bool'\n",
      "        Check if DataBase has named table.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        table_name: string\n",
      "            Name of SQL table.\n",
      "        con: ADBC Connection, SQLAlchemy connectable, str, or sqlite3 connection\n",
      "            ADBC provides high performance I/O with native type support, where available.\n",
      "            Using SQLAlchemy makes it possible to use any DB supported by that\n",
      "            library.\n",
      "            If a DBAPI2 object, only sqlite3 is supported.\n",
      "        schema : string, default None\n",
      "            Name of SQL schema in database to write to (if database flavor supports\n",
      "            this). If None, use default schema (default).\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        boolean\n",
      "\n",
      "    to_sql(\n",
      "        frame,\n",
      "        name: 'str',\n",
      "        con,\n",
      "        schema: 'str | None' = None,\n",
      "        if_exists: \"Literal['fail', 'replace', 'append']\" = 'fail',\n",
      "        index: 'bool' = True,\n",
      "        index_label: 'IndexLabel | None' = None,\n",
      "        chunksize: 'int | None' = None,\n",
      "        dtype: 'DtypeArg | None' = None,\n",
      "        method: \"Literal['multi'] | Callable | None\" = None,\n",
      "        engine: 'str' = 'auto',\n",
      "        **engine_kwargs\n",
      "    ) -> 'int | None'\n",
      "        Write records stored in a DataFrame to a SQL database.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        frame : DataFrame, Series\n",
      "        name : str\n",
      "            Name of SQL table.\n",
      "        con : ADBC Connection, SQLAlchemy connectable, str, or sqlite3 connection\n",
      "            or sqlite3 DBAPI2 connection\n",
      "            ADBC provides high performance I/O with native type support, where available.\n",
      "            Using SQLAlchemy makes it possible to use any DB supported by that\n",
      "            library.\n",
      "            If a DBAPI2 object, only sqlite3 is supported.\n",
      "        schema : str, optional\n",
      "            Name of SQL schema in database to write to (if database flavor\n",
      "            supports this). If None, use default schema (default).\n",
      "        if_exists : {'fail', 'replace', 'append'}, default 'fail'\n",
      "            - fail: If table exists, do nothing.\n",
      "            - replace: If table exists, drop it, recreate it, and insert data.\n",
      "            - append: If table exists, insert data. Create if does not exist.\n",
      "        index : bool, default True\n",
      "            Write DataFrame index as a column.\n",
      "        index_label : str or sequence, optional\n",
      "            Column label for index column(s). If None is given (default) and\n",
      "            `index` is True, then the index names are used.\n",
      "            A sequence should be given if the DataFrame uses MultiIndex.\n",
      "        chunksize : int, optional\n",
      "            Specify the number of rows in each batch to be written at a time.\n",
      "            By default, all rows will be written at once.\n",
      "        dtype : dict or scalar, optional\n",
      "            Specifying the datatype for columns. If a dictionary is used, the\n",
      "            keys should be the column names and the values should be the\n",
      "            SQLAlchemy types or strings for the sqlite3 fallback mode. If a\n",
      "            scalar is provided, it will be applied to all columns.\n",
      "        method : {None, 'multi', callable}, optional\n",
      "            Controls the SQL insertion clause used:\n",
      "\n",
      "            - None : Uses standard SQL ``INSERT`` clause (one per row).\n",
      "            - ``'multi'``: Pass multiple values in a single ``INSERT`` clause.\n",
      "            - callable with signature ``(pd_table, conn, keys, data_iter) -> int | None``.\n",
      "\n",
      "            Details and a sample callable implementation can be found in the\n",
      "            section :ref:`insert method <io.sql.method>`.\n",
      "        engine : {'auto', 'sqlalchemy'}, default 'auto'\n",
      "            SQL engine library to use. If 'auto', then the option\n",
      "            ``io.sql.engine`` is used. The default ``io.sql.engine``\n",
      "            behavior is 'sqlalchemy'\n",
      "\n",
      "            .. versionadded:: 1.3.0\n",
      "\n",
      "        **engine_kwargs\n",
      "            Any additional kwargs are passed to the engine.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        None or int\n",
      "            Number of rows affected by to_sql. None is returned if the callable\n",
      "            passed into ``method`` does not return an integer number of rows.\n",
      "\n",
      "            .. versionadded:: 1.4.0\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        The returned rows affected is the sum of the ``rowcount`` attribute of ``sqlite3.Cursor``\n",
      "        or SQLAlchemy connectable. If using ADBC the returned rows are the result\n",
      "        of ``Cursor.adbc_ingest``. The returned value may not reflect the exact number of written\n",
      "        rows as stipulated in the\n",
      "        `sqlite3 <https://docs.python.org/3/library/sqlite3.html#sqlite3.Cursor.rowcount>`__ or\n",
      "        `SQLAlchemy <https://docs.sqlalchemy.org/en/14/core/connections.html#sqlalchemy.engine.BaseCursorResult.rowcount>`__\n",
      "\n",
      "DATA\n",
      "    Callable = typing.Callable\n",
      "        Deprecated alias to collections.abc.Callable.\n",
      "\n",
      "        Callable[[int], str] signifies a function that takes a single\n",
      "        parameter of type int and returns a str.\n",
      "\n",
      "        The subscription syntax must always be used with exactly two\n",
      "        values: the argument list and the return type.\n",
      "        The argument list must be a list of types, a ParamSpec,\n",
      "        Concatenate or ellipsis. The return type must be a single type.\n",
      "\n",
      "        There is no syntax to indicate optional or keyword arguments;\n",
      "        such function types are rarely used as callback types.\n",
      "\n",
      "    Literal = typing.Literal\n",
      "        Special typing form to define literal types (a.k.a. value types).\n",
      "\n",
      "        This form can be used to indicate to type checkers that the corresponding\n",
      "        variable or function parameter has a value equivalent to the provided\n",
      "        literal (or one of several literals)::\n",
      "\n",
      "            def validate_simple(data: Any) -> Literal[True]:  # always returns True\n",
      "                ...\n",
      "\n",
      "            MODE = Literal['r', 'rb', 'w', 'wb']\n",
      "            def open_helper(file: str, mode: MODE) -> str:\n",
      "                ...\n",
      "\n",
      "            open_helper('/some/path', 'r')  # Passes type check\n",
      "            open_helper('/other/path', 'typo')  # Error in type checker\n",
      "\n",
      "        Literal[...] cannot be subclassed. At runtime, an arbitrary value\n",
      "        is allowed as type argument to Literal[...], but type checkers may\n",
      "        impose restrictions.\n",
      "\n",
      "    TYPE_CHECKING = False\n",
      "    get_option = <pandas._config.config.CallableDynamicDoc object>\n",
      "        get_option(pat)\n",
      "\n",
      "        Retrieves the value of the specified option.\n",
      "\n",
      "        Available options:\n",
      "\n",
      "        - compute.[use_bottleneck, use_numba, use_numexpr]\n",
      "        - display.[chop_threshold, colheader_justify, date_dayfirst, date_yearfirst,\n",
      "          encoding, expand_frame_repr, float_format]\n",
      "        - display.html.[border, table_schema, use_mathjax]\n",
      "        - display.[large_repr, max_categories, max_columns, max_colwidth, max_dir_items,\n",
      "          max_info_columns, max_info_rows, max_rows, max_seq_items, memory_usage,\n",
      "          min_rows, multi_sparse, notebook_repr_html, pprint_nest_depth, precision,\n",
      "          show_dimensions]\n",
      "        - display.unicode.[ambiguous_as_wide, east_asian_width]\n",
      "        - display.[width]\n",
      "        - future.[infer_string, no_silent_downcasting]\n",
      "        - io.excel.ods.[reader, writer]\n",
      "        - io.excel.xls.[reader]\n",
      "        - io.excel.xlsb.[reader]\n",
      "        - io.excel.xlsm.[reader, writer]\n",
      "        - io.excel.xlsx.[reader, writer]\n",
      "        - io.hdf.[default_format, dropna_table]\n",
      "        - io.parquet.[engine]\n",
      "        - io.sql.[engine]\n",
      "        - mode.[chained_assignment, copy_on_write, data_manager, sim_interactive,\n",
      "          string_storage, use_inf_as_na]\n",
      "        - plotting.[backend]\n",
      "        - plotting.matplotlib.[register_converters]\n",
      "        - styler.format.[decimal, escape, formatter, na_rep, precision, thousands]\n",
      "        - styler.html.[mathjax]\n",
      "        - styler.latex.[environment, hrules, multicol_align, multirow_align]\n",
      "        - styler.render.[encoding, max_columns, max_elements, max_rows, repr]\n",
      "        - styler.sparse.[columns, index]\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        pat : str\n",
      "            Regexp which should match a single option.\n",
      "            Note: partial matches are supported for convenience, but unless you use the\n",
      "            full option name (e.g. x.y.z.option_name), your code may break in future\n",
      "            versions if new options with similar names are introduced.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        result : the value of the option\n",
      "\n",
      "        Raises\n",
      "        ------\n",
      "        OptionError : if no such option exists\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        Please reference the :ref:`User Guide <options>` for more information.\n",
      "\n",
      "        The available options with its descriptions:\n",
      "\n",
      "        compute.use_bottleneck : bool\n",
      "            Use the bottleneck library to accelerate if it is installed,\n",
      "            the default is True\n",
      "            Valid values: False,True\n",
      "            [default: True] [currently: True]\n",
      "        compute.use_numba : bool\n",
      "            Use the numba engine option for select operations if it is installed,\n",
      "            the default is False\n",
      "            Valid values: False,True\n",
      "            [default: False] [currently: False]\n",
      "        compute.use_numexpr : bool\n",
      "            Use the numexpr library to accelerate computation if it is installed,\n",
      "            the default is True\n",
      "            Valid values: False,True\n",
      "            [default: True] [currently: True]\n",
      "        display.chop_threshold : float or None\n",
      "            if set to a float value, all float values smaller than the given threshold\n",
      "            will be displayed as exactly 0 by repr and friends.\n",
      "            [default: None] [currently: None]\n",
      "        display.colheader_justify : 'left'/'right'\n",
      "            Controls the justification of column headers. used by DataFrameFormatter.\n",
      "            [default: right] [currently: right]\n",
      "        display.date_dayfirst : boolean\n",
      "            When True, prints and parses dates with the day first, eg 20/01/2005\n",
      "            [default: False] [currently: False]\n",
      "        display.date_yearfirst : boolean\n",
      "            When True, prints and parses dates with the year first, eg 2005/01/20\n",
      "            [default: False] [currently: False]\n",
      "        display.encoding : str/unicode\n",
      "            Defaults to the detected encoding of the console.\n",
      "            Specifies the encoding to be used for strings returned by to_string,\n",
      "            these are generally strings meant to be displayed on the console.\n",
      "            [default: UTF-8] [currently: UTF-8]\n",
      "        display.expand_frame_repr : boolean\n",
      "            Whether to print out the full DataFrame repr for wide DataFrames across\n",
      "            multiple lines, `max_columns` is still respected, but the output will\n",
      "            wrap-around across multiple \"pages\" if its width exceeds `display.width`.\n",
      "            [default: True] [currently: True]\n",
      "        display.float_format : callable\n",
      "            The callable should accept a floating point number and return\n",
      "            a string with the desired format of the number. This is used\n",
      "            in some places like SeriesFormatter.\n",
      "            See formats.format.EngFormatter for an example.\n",
      "            [default: None] [currently: None]\n",
      "        display.html.border : int\n",
      "            A ``border=value`` attribute is inserted in the ``<table>`` tag\n",
      "            for the DataFrame HTML repr.\n",
      "            [default: 1] [currently: 1]\n",
      "        display.html.table_schema : boolean\n",
      "            Whether to publish a Table Schema representation for frontends\n",
      "            that support it.\n",
      "            (default: False)\n",
      "            [default: False] [currently: False]\n",
      "        display.html.use_mathjax : boolean\n",
      "            When True, Jupyter notebook will process table contents using MathJax,\n",
      "            rendering mathematical expressions enclosed by the dollar symbol.\n",
      "            (default: True)\n",
      "            [default: True] [currently: True]\n",
      "        display.large_repr : 'truncate'/'info'\n",
      "            For DataFrames exceeding max_rows/max_cols, the repr (and HTML repr) can\n",
      "            show a truncated table, or switch to the view from\n",
      "            df.info() (the behaviour in earlier versions of pandas).\n",
      "            [default: truncate] [currently: truncate]\n",
      "        display.max_categories : int\n",
      "            This sets the maximum number of categories pandas should output when\n",
      "            printing out a `Categorical` or a Series of dtype \"category\".\n",
      "            [default: 8] [currently: 8]\n",
      "        display.max_columns : int\n",
      "            If max_cols is exceeded, switch to truncate view. Depending on\n",
      "            `large_repr`, objects are either centrally truncated or printed as\n",
      "            a summary view. 'None' value means unlimited.\n",
      "\n",
      "            In case python/IPython is running in a terminal and `large_repr`\n",
      "            equals 'truncate' this can be set to 0 or None and pandas will auto-detect\n",
      "            the width of the terminal and print a truncated object which fits\n",
      "            the screen width. The IPython notebook, IPython qtconsole, or IDLE\n",
      "            do not run in a terminal and hence it is not possible to do\n",
      "            correct auto-detection and defaults to 20.\n",
      "            [default: 20] [currently: 20]\n",
      "        display.max_colwidth : int or None\n",
      "            The maximum width in characters of a column in the repr of\n",
      "            a pandas data structure. When the column overflows, a \"...\"\n",
      "            placeholder is embedded in the output. A 'None' value means unlimited.\n",
      "            [default: 50] [currently: 50]\n",
      "        display.max_dir_items : int\n",
      "            The number of items that will be added to `dir(...)`. 'None' value means\n",
      "            unlimited. Because dir is cached, changing this option will not immediately\n",
      "            affect already existing dataframes until a column is deleted or added.\n",
      "\n",
      "            This is for instance used to suggest columns from a dataframe to tab\n",
      "            completion.\n",
      "            [default: 100] [currently: 100]\n",
      "        display.max_info_columns : int\n",
      "            max_info_columns is used in DataFrame.info method to decide if\n",
      "            per column information will be printed.\n",
      "            [default: 100] [currently: 100]\n",
      "        display.max_info_rows : int\n",
      "            df.info() will usually show null-counts for each column.\n",
      "            For large frames this can be quite slow. max_info_rows and max_info_cols\n",
      "            limit this null check only to frames with smaller dimensions than\n",
      "            specified.\n",
      "            [default: 1690785] [currently: 1690785]\n",
      "        display.max_rows : int\n",
      "            If max_rows is exceeded, switch to truncate view. Depending on\n",
      "            `large_repr`, objects are either centrally truncated or printed as\n",
      "            a summary view. 'None' value means unlimited.\n",
      "\n",
      "            In case python/IPython is running in a terminal and `large_repr`\n",
      "            equals 'truncate' this can be set to 0 and pandas will auto-detect\n",
      "            the height of the terminal and print a truncated object which fits\n",
      "            the screen height. The IPython notebook, IPython qtconsole, or\n",
      "            IDLE do not run in a terminal and hence it is not possible to do\n",
      "            correct auto-detection.\n",
      "            [default: 60] [currently: 60]\n",
      "        display.max_seq_items : int or None\n",
      "            When pretty-printing a long sequence, no more then `max_seq_items`\n",
      "            will be printed. If items are omitted, they will be denoted by the\n",
      "            addition of \"...\" to the resulting string.\n",
      "\n",
      "            If set to None, the number of items to be printed is unlimited.\n",
      "            [default: 100] [currently: 100]\n",
      "        display.memory_usage : bool, string or None\n",
      "            This specifies if the memory usage of a DataFrame should be displayed when\n",
      "            df.info() is called. Valid values True,False,'deep'\n",
      "            [default: True] [currently: True]\n",
      "        display.min_rows : int\n",
      "            The numbers of rows to show in a truncated view (when `max_rows` is\n",
      "            exceeded). Ignored when `max_rows` is set to None or 0. When set to\n",
      "            None, follows the value of `max_rows`.\n",
      "            [default: 10] [currently: 10]\n",
      "        display.multi_sparse : boolean\n",
      "            \"sparsify\" MultiIndex display (don't display repeated\n",
      "            elements in outer levels within groups)\n",
      "            [default: True] [currently: True]\n",
      "        display.notebook_repr_html : boolean\n",
      "            When True, IPython notebook will use html representation for\n",
      "            pandas objects (if it is available).\n",
      "            [default: True] [currently: True]\n",
      "        display.pprint_nest_depth : int\n",
      "            Controls the number of nested levels to process when pretty-printing\n",
      "            [default: 3] [currently: 3]\n",
      "        display.precision : int\n",
      "            Floating point output precision in terms of number of places after the\n",
      "            decimal, for regular formatting as well as scientific notation. Similar\n",
      "            to ``precision`` in :meth:`numpy.set_printoptions`.\n",
      "            [default: 6] [currently: 6]\n",
      "        display.show_dimensions : boolean or 'truncate'\n",
      "            Whether to print out dimensions at the end of DataFrame repr.\n",
      "            If 'truncate' is specified, only print out the dimensions if the\n",
      "            frame is truncated (e.g. not display all rows and/or columns)\n",
      "            [default: truncate] [currently: truncate]\n",
      "        display.unicode.ambiguous_as_wide : boolean\n",
      "            Whether to use the Unicode East Asian Width to calculate the display text\n",
      "            width.\n",
      "            Enabling this may affect to the performance (default: False)\n",
      "            [default: False] [currently: False]\n",
      "        display.unicode.east_asian_width : boolean\n",
      "            Whether to use the Unicode East Asian Width to calculate the display text\n",
      "            width.\n",
      "            Enabling this may affect to the performance (default: False)\n",
      "            [default: False] [currently: False]\n",
      "        display.width : int\n",
      "            Width of the display in characters. In case python/IPython is running in\n",
      "            a terminal this can be set to None and pandas will correctly auto-detect\n",
      "            the width.\n",
      "            Note that the IPython notebook, IPython qtconsole, or IDLE do not run in a\n",
      "            terminal and hence it is not possible to correctly detect the width.\n",
      "            [default: 80] [currently: 80]\n",
      "        future.infer_string Whether to infer sequence of str objects as pyarrow string dtype, which will be the default in pandas 3.0 (at which point this option will be deprecated).\n",
      "            [default: False] [currently: False]\n",
      "        future.no_silent_downcasting Whether to opt-in to the future behavior which will *not* silently downcast results from Series and DataFrame `where`, `mask`, and `clip` methods. Silent downcasting will be removed in pandas 3.0 (at which point this option will be deprecated).\n",
      "            [default: False] [currently: False]\n",
      "        io.excel.ods.reader : string\n",
      "            The default Excel reader engine for 'ods' files. Available options:\n",
      "            auto, odf, calamine.\n",
      "            [default: auto] [currently: auto]\n",
      "        io.excel.ods.writer : string\n",
      "            The default Excel writer engine for 'ods' files. Available options:\n",
      "            auto, odf.\n",
      "            [default: auto] [currently: auto]\n",
      "        io.excel.xls.reader : string\n",
      "            The default Excel reader engine for 'xls' files. Available options:\n",
      "            auto, xlrd, calamine.\n",
      "            [default: auto] [currently: auto]\n",
      "        io.excel.xlsb.reader : string\n",
      "            The default Excel reader engine for 'xlsb' files. Available options:\n",
      "            auto, pyxlsb, calamine.\n",
      "            [default: auto] [currently: auto]\n",
      "        io.excel.xlsm.reader : string\n",
      "            The default Excel reader engine for 'xlsm' files. Available options:\n",
      "            auto, xlrd, openpyxl, calamine.\n",
      "            [default: auto] [currently: auto]\n",
      "        io.excel.xlsm.writer : string\n",
      "            The default Excel writer engine for 'xlsm' files. Available options:\n",
      "            auto, openpyxl.\n",
      "            [default: auto] [currently: auto]\n",
      "        io.excel.xlsx.reader : string\n",
      "            The default Excel reader engine for 'xlsx' files. Available options:\n",
      "            auto, xlrd, openpyxl, calamine.\n",
      "            [default: auto] [currently: auto]\n",
      "        io.excel.xlsx.writer : string\n",
      "            The default Excel writer engine for 'xlsx' files. Available options:\n",
      "            auto, openpyxl, xlsxwriter.\n",
      "            [default: auto] [currently: auto]\n",
      "        io.hdf.default_format : format\n",
      "            default format writing format, if None, then\n",
      "            put will default to 'fixed' and append will default to 'table'\n",
      "            [default: None] [currently: None]\n",
      "        io.hdf.dropna_table : boolean\n",
      "            drop ALL nan rows when appending to a table\n",
      "            [default: False] [currently: False]\n",
      "        io.parquet.engine : string\n",
      "            The default parquet reader/writer engine. Available options:\n",
      "            'auto', 'pyarrow', 'fastparquet', the default is 'auto'\n",
      "            [default: auto] [currently: auto]\n",
      "        io.sql.engine : string\n",
      "            The default sql reader/writer engine. Available options:\n",
      "            'auto', 'sqlalchemy', the default is 'auto'\n",
      "            [default: auto] [currently: auto]\n",
      "        mode.chained_assignment : string\n",
      "            Raise an exception, warn, or no action if trying to use chained assignment,\n",
      "            The default is warn\n",
      "            [default: warn] [currently: warn]\n",
      "        mode.copy_on_write : bool\n",
      "            Use new copy-view behaviour using Copy-on-Write. Defaults to False,\n",
      "            unless overridden by the 'PANDAS_COPY_ON_WRITE' environment variable\n",
      "            (if set to \"1\" for True, needs to be set before pandas is imported).\n",
      "            [default: False] [currently: False]\n",
      "        mode.data_manager : string\n",
      "            Internal data manager type; can be \"block\" or \"array\". Defaults to \"block\",\n",
      "            unless overridden by the 'PANDAS_DATA_MANAGER' environment variable (needs\n",
      "            to be set before pandas is imported).\n",
      "            [default: block] [currently: block]\n",
      "            (Deprecated, use `` instead.)\n",
      "        mode.sim_interactive : boolean\n",
      "            Whether to simulate interactive mode for purposes of testing\n",
      "            [default: False] [currently: False]\n",
      "        mode.string_storage : string\n",
      "            The default storage for StringDtype. This option is ignored if\n",
      "            ``future.infer_string`` is set to True.\n",
      "            [default: python] [currently: python]\n",
      "        mode.use_inf_as_na : boolean\n",
      "            True means treat None, NaN, INF, -INF as NA (old way),\n",
      "            False means None and NaN are null, but INF, -INF are not NA\n",
      "            (new way).\n",
      "\n",
      "            This option is deprecated in pandas 2.1.0 and will be removed in 3.0.\n",
      "            [default: False] [currently: False]\n",
      "            (Deprecated, use `` instead.)\n",
      "        plotting.backend : str\n",
      "            The plotting backend to use. The default value is \"matplotlib\", the\n",
      "            backend provided with pandas. Other backends can be specified by\n",
      "            providing the name of the module that implements the backend.\n",
      "            [default: matplotlib] [currently: matplotlib]\n",
      "        plotting.matplotlib.register_converters : bool or 'auto'.\n",
      "            Whether to register converters with matplotlib's units registry for\n",
      "            dates, times, datetimes, and Periods. Toggling to False will remove\n",
      "            the converters, restoring any converters that pandas overwrote.\n",
      "            [default: auto] [currently: auto]\n",
      "        styler.format.decimal : str\n",
      "            The character representation for the decimal separator for floats and complex.\n",
      "            [default: .] [currently: .]\n",
      "        styler.format.escape : str, optional\n",
      "            Whether to escape certain characters according to the given context; html or latex.\n",
      "            [default: None] [currently: None]\n",
      "        styler.format.formatter : str, callable, dict, optional\n",
      "            A formatter object to be used as default within ``Styler.format``.\n",
      "            [default: None] [currently: None]\n",
      "        styler.format.na_rep : str, optional\n",
      "            The string representation for values identified as missing.\n",
      "            [default: None] [currently: None]\n",
      "        styler.format.precision : int\n",
      "            The precision for floats and complex numbers.\n",
      "            [default: 6] [currently: 6]\n",
      "        styler.format.thousands : str, optional\n",
      "            The character representation for thousands separator for floats, int and complex.\n",
      "            [default: None] [currently: None]\n",
      "        styler.html.mathjax : bool\n",
      "            If False will render special CSS classes to table attributes that indicate Mathjax\n",
      "            will not be used in Jupyter Notebook.\n",
      "            [default: True] [currently: True]\n",
      "        styler.latex.environment : str\n",
      "            The environment to replace ``\\begin{table}``. If \"longtable\" is used results\n",
      "            in a specific longtable environment format.\n",
      "            [default: None] [currently: None]\n",
      "        styler.latex.hrules : bool\n",
      "            Whether to add horizontal rules on top and bottom and below the headers.\n",
      "            [default: False] [currently: False]\n",
      "        styler.latex.multicol_align : {\"r\", \"c\", \"l\", \"naive-l\", \"naive-r\"}\n",
      "            The specifier for horizontal alignment of sparsified LaTeX multicolumns. Pipe\n",
      "            decorators can also be added to non-naive values to draw vertical\n",
      "            rules, e.g. \"\\|r\" will draw a rule on the left side of right aligned merged cells.\n",
      "            [default: r] [currently: r]\n",
      "        styler.latex.multirow_align : {\"c\", \"t\", \"b\"}\n",
      "            The specifier for vertical alignment of sparsified LaTeX multirows.\n",
      "            [default: c] [currently: c]\n",
      "        styler.render.encoding : str\n",
      "            The encoding used for output HTML and LaTeX files.\n",
      "            [default: utf-8] [currently: utf-8]\n",
      "        styler.render.max_columns : int, optional\n",
      "            The maximum number of columns that will be rendered. May still be reduced to\n",
      "            satisfy ``max_elements``, which takes precedence.\n",
      "            [default: None] [currently: None]\n",
      "        styler.render.max_elements : int\n",
      "            The maximum number of data-cell (<td>) elements that will be rendered before\n",
      "            trimming will occur over columns, rows or both if needed.\n",
      "            [default: 262144] [currently: 262144]\n",
      "        styler.render.max_rows : int, optional\n",
      "            The maximum number of rows that will be rendered. May still be reduced to\n",
      "            satisfy ``max_elements``, which takes precedence.\n",
      "            [default: None] [currently: None]\n",
      "        styler.render.repr : str\n",
      "            Determine which output to use in Jupyter Notebook in {\"html\", \"latex\"}.\n",
      "            [default: html] [currently: html]\n",
      "        styler.sparse.columns : bool\n",
      "            Whether to sparsify the display of hierarchical columns. Setting to False will\n",
      "            display each explicit level element in a hierarchical key for each column.\n",
      "            [default: True] [currently: True]\n",
      "        styler.sparse.index : bool\n",
      "            Whether to sparsify the display of a hierarchical index. Setting to False will\n",
      "            display each explicit level element in a hierarchical key for each row.\n",
      "            [default: True] [currently: True]\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> pd.get_option('display.max_columns')  # doctest: +SKIP\n",
      "        4\n",
      "\n",
      "FILE\n",
      "    c:\\program files\\python313\\lib\\site-packages\\pandas\\io\\sql.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(psql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47e3c85f-9d80-43bf-bd0b-b1d4f6b46e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\D510\\AppData\\Local\\Temp\\ipykernel_16404\\3917142143.py:1: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = psql.read_sql('SELECT * FROM volt_table', conn) # def: DataFrame\n"
     ]
    }
   ],
   "source": [
    "df = psql.read_sql('SELECT * FROM volt_table', conn) # def: DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5422abc0-edb8-47d9-8160-2bdb6a26f9b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfbaee5c-d090-4b09-a078-f2f6595e124b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>meas_time</th>\n",
       "      <th>volt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.731542e+09</td>\n",
       "      <td>1.731542e+09</td>\n",
       "      <td>3.301245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.985248e+05</td>\n",
       "      <td>2.985248e+05</td>\n",
       "      <td>0.003237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.731307e+09</td>\n",
       "      <td>1.731307e+09</td>\n",
       "      <td>3.299120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.731309e+09</td>\n",
       "      <td>1.731309e+09</td>\n",
       "      <td>3.299120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.731309e+09</td>\n",
       "      <td>1.731309e+09</td>\n",
       "      <td>3.299120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.731907e+09</td>\n",
       "      <td>1.731907e+09</td>\n",
       "      <td>3.304008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.731907e+09</td>\n",
       "      <td>1.731907e+09</td>\n",
       "      <td>3.308896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     meas_time       volt\n",
       "count  2.300000e+01  2.300000e+01  23.000000\n",
       "mean   1.731542e+09  1.731542e+09   3.301245\n",
       "std    2.985248e+05  2.985248e+05   0.003237\n",
       "min    1.731307e+09  1.731307e+09   3.299120\n",
       "25%    1.731309e+09  1.731309e+09   3.299120\n",
       "50%    1.731309e+09  1.731309e+09   3.299120\n",
       "75%    1.731907e+09  1.731907e+09   3.304008\n",
       "max    1.731907e+09  1.731907e+09   3.308896"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe() # DataFrame을 묘사하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc511319-8b22-4916-b433-80b39046951a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seriesId = df['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c01799ee-0acd-4b63-bc29-9f73bdb092f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(seriesId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37b97584-c809-473c-9aaf-03f65214983e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     1731306892\n",
      "1     1731306902\n",
      "2     1731307246\n",
      "3     1731307251\n",
      "4     1731308828\n",
      "5     1731308830\n",
      "6     1731308832\n",
      "7     1731308834\n",
      "8     1731308836\n",
      "9     1731308839\n",
      "10    1731308841\n",
      "11    1731308843\n",
      "12    1731308845\n",
      "13    1731308847\n",
      "14    1731906558\n",
      "15    1731906560\n",
      "16    1731906562\n",
      "17    1731906563\n",
      "18    1731906565\n",
      "19    1731906567\n",
      "20    1731906568\n",
      "21    1731906570\n",
      "22    1731906572\n",
      "Name: id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(seriesId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9f22f9d-8340-4030-87f2-4d5d2d4d5cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "seriesVolt = df['volt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71aefbde-697a-4eb1-b4a3-f17df0238986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     3.308896\n",
      "1     3.304008\n",
      "2     3.308896\n",
      "3     3.304008\n",
      "4     3.304008\n",
      "5     3.299120\n",
      "6     3.299120\n",
      "7     3.299120\n",
      "8     3.304008\n",
      "9     3.299120\n",
      "10    3.299120\n",
      "11    3.299120\n",
      "12    3.299120\n",
      "13    3.299120\n",
      "14    3.304008\n",
      "15    3.299120\n",
      "16    3.299120\n",
      "17    3.299120\n",
      "18    3.299120\n",
      "19    3.299120\n",
      "20    3.304008\n",
      "21    3.299120\n",
      "22    3.299120\n",
      "Name: volt, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(seriesVolt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5d8f5bc-5428-4d91-a7e1-f13a9e0e7e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3.301245443478261)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seriesVolt.mean() # 평균값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e24caefe-4be3-4de3-b8b8-b46e8aac68d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3.3088956)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seriesVolt.max() # 최대값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7772382d-909b-4e0d-b19a-8c58bc3cd06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.0480783981660047e-05)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seriesVolt.var() # 분산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "636c2ade-d61b-4292-8802-5de7e524ba6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0032374038953550495)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seriesVolt.std() # 표준 편차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b1f651-25ba-4839-83ef-175c432e7f48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
